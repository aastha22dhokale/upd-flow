2: ingested record multiplication  The number of records processed multiplies due to:  • Disaggregation by the Data Ingestor of composite Party records into atomic Party records.  • Model transformation into objects & relationships  • Upload formats (different OIL files for Parties and relationships, multiple API endpoints for different entities within a single  Involved Party object (postal address, name, …)  15  Leading to a large number of overall transactions to execute in the end repository leading to longer throughput times. Constraint 3: multiple repositories that are updated sequentially  From the single ingested files, we must update 4 data stores  which are sequentially dependent.  Updates of the Main data zones may only happen after updates in  the External zones happened as the External zones are considered  “Master” for external ingested data.  MADP objects are dependent on their creation in OnePAM first,  capturing the OnePAM UUID and then creating MADP objects,  The sequential nature also requires use to obtain the confirmation  of uploads before moving on to the next zone, as well as to ensure  only successful uploaded records/ attributes are propagated so no  inconsistencies arise.  This increases the end-to-end throughput times of uploads  16  referencing this OnePAM UUID. Constraint 4: Limited time windows  Allowable time frame  00:00  08:00  12:00  16:00  24:00  OnePAM has time-of-day constraints because, as an interactive production system, it has spikes during certain hours of the day. In the  architecture of OnePAM there is currently no difference between batch and interactive traffic.  Our volume-based updates should not interfere with customers and employees using the system. Smaller uploads will not impact  normal operations, but larger daily uploads should happen in the quiet hours.  Very large initial loads must be handled manually and planned by the OIL team of OnePAM and not be uploaded using automated  means.  17  Should not be a constraint anymore in OnePAM NG Constraint 5: Slow upload throughput  This is the  single most  determining  throughput  factor  3-5 RPS  5 TPS  OnePAM OIL & Fact Write APIs are by default constraint in # records per second (RPS) & transactions per second (TPS) respectively,  putting upper boundaries on what can be processed within a given time period.  The cumulative effect of daily multiple file uploads, some large, record & call multiplication, serialized uploads to multiple  data stores, limited time windows and slow upload throughputs create real issues to ensure updates can be made within  the required time windows.  18  Should not be a constraint anymore in OnePAM NG Table of Content  Part 1 – High-level architecture  1. Context  2. Constraints & mitigation strategies  • Environmental constraints  • Mitigation strategies  3. High-level Architecture  • Data Distributor  • Data Refresher & Reconciler intro  • Data Refresher  • Data Reconciler  4. Architecture decisions, risks & open points  Part 2 – Phased approach & Patterns  1. Phase & Pattern overview  2. Phase 1: OnePAM External LDD Upload  3. Phase 2: OnePAM Main LDD Update  4. Phase 3: add MADP  • Phase 3a: MADP External DD Upload  • Phase 3b: MADP Main DD Update  Part 3 – Detailed architecture  1. OnePAM & MADP Detailed Architecture  2. Data fragmentation, Model Transformation,  Filtering & deduplication  3. OnePAM/MADP attribute mapping and  reading & updating  4. OnePAM API, OIL & Notifications  5. OnePAM Main LDD Involved Party  identification & Self-healing  6. MADP uploads  7. Human Process interaction  8. End-to-End architecture view  19 Strategy 1: Request higher throughput rates to OnePAM  5 Strategies to alleviate the constraints  25 RPS  25 TPS  We request to use higher throughput rates (25 TPS  & RPS) for APIs and OIL respectively.  This is in principle possible but must be agreed with GCDM.  The question has been asked but no answer yet, and this must be followed-up on.  20 Strategy 2: Filtering out unchanged Party records & attributes  5 Strategies to alleviate the constraints  Data Ingestor prunes the set of ingested disaggregated, atomic Party records of all unchanged records, and we process only  disaggregated records with changes.  This reduces the total number of records to process. However it will still be a multiple of the ingested number of composite records as  all of them have at least one change, and most have relationships to other Party objects.  21  This is an architecture decision: we don’t update or even ‘touch’ data that didn’t change Strategy 3: Flow parallelization  5 Strategies to alleviate the constraints  We parallel update OnePAM and MADP Landing & Main zones respectively to reduce end-to-end throughput time. But there are  conditions to achieve this.  There is a constraint where MADP requires a OnePAM UUID for all “Local” attributes when uploading, also for new Parties. We do know  what ingested records are new before uploading as we will read all current Party objects in OnePAM upfront through entity matching*  and a miss indicates a new Party that must be created.  OnePAM has a feature** to define new UUIDs outside OnePAM for new Parties before creating them inside OnePAM. To enable this,  we must raise a feature request with GCDM. This will take some time & justification.  If we can use this feature, we can upload data to OnePAM and MADP in parallel as we know all UUIDs upfront.  22  * Entity Matching is the using of information in the ingested atomic Party record (like Legal Entity number, or demographics) to unambiguously identify a Party object in OnePAM and obtain the OnePAM UUID.  ** Only enabled for Austrialia and only for OIL and the Fact API endpoints Austrialia uses Strategy 4: out-of-band processing for refreshes & reconciliations  5 Strategies to alleviate the constraints  Refresher  Unite  Data Lake  (UDL)  upload  MADP  External DD  Ingested Party Records:  Disaggregated ING  formatted & enriched  Preprocess External  Upload  Upload  Upload  OnePAM  External LDD  Unite  Data Lake  (UDL)  Reconciler  Preprocess Main  Update  Continue only  with successful  uploaded records*  Update MADP  Main DDs  Update  Update  OnePAM Main  LDD  Refreshes & Reconciliations require us to process ALL data in OnePAM and MADP which, given the constraints of OnePAM is  impractical to execute directly on the operational system. Most activity, once the full dataset is extracted, is comparing either Ingested  data with the External zones, or compare Main and External Zones, respectively. Only differences between them must be uploaded to  the External zones, or Main zones respectively.  We will process the data out-of-band, by using the Unite Data Lake (UDL), with only actual differences to be processed into  OnePAM/MADP, turning it into a delta that is treated like a load done daily (albeit on steroids).  For this we introduce 2 new components (which, in implementation could be a single one):  • The Refresher: compares external ingested full datasets with what is in the UDL copied OnePAM/MADP External zones  23  • The Reconciler: compares the data between the in the UDL copied OnePAM/MADP External and Main zones. Strategy 5: Phase-based implementation approach  5 Strategies to alleviate the constraints  Not all enablers to cope with the constraints have been guaranteed yet by GCDM for OnePAM, higher TPS/RPS & externally defined  OnePAM UUIDs. 
 But we don’t need to have the full possible architecture available from the start (Big Design Up Front).  • There have been no “Local” attributes identified in the current ingested files (Legal Entities, Operating Sites, Legal representatives,  Bankruptcies & Incapables). That means we don’t need MADP (for now), nor the functionality to create OnePAM UUIDs outside  OnePAM.  • We don’t Update Involved Party data to the OnePAM Main LDD until later, so for now, given current volumes, with only updating the  OnePAM External LDD we don’t necessarily need the 25 TPS/RPS for daily updates (for initial loads it would be nice but initial loads are  not that time sensitive and can happen over multiple days).  This allows us to create an evolutionary architecture that provides the required functionality over time a.) when it is needed, and b.) after  we obtained the buy-in of GCDM and subsequent enablement of the features.  24 Table of Content  Part 1 – High-level architecture  1. Context  2. Constraints & mitigation strategies  • Environmental constraints  • Mitigation strategies  3. High-level Architecture  • Data Distributor  • Data Refresher & Reconciler intro  • Data Refresher  • Data Reconciler  4. Architecture decisions, risks & open points  Part 2 – Phased approach & Patterns  1. Phase & Pattern overview  2. Phase 1: OnePAM External LDD Upload  3. Phase 2: OnePAM Main LDD Update  4. Phase 3: add MADP  • Phase 3a: MADP External DD Upload  • Phase 3b: MADP Main DD Update  Part 3 – Detailed architecture  1. OnePAM & MADP Detailed Architecture  2. Data fragmentation, Model Transformation,  Filtering & deduplication  3. OnePAM/MADP attribute mapping and  reading & updating  4. OnePAM API, OIL & Notifications  5. OnePAM Main LDD Involved Party  identification & Self-healing  6. MADP uploads  7. Human Process interaction  8. End-to-End architecture view  25 Data Distributor Architecture Solution Principles  1. The Data Ingestor converts external ingested Party data into a suitable format for the Data Distributor to consume.  • It does not apply business logic to the ingested Party data.  2. The Data Distributor updates the Party Data Platform with external ingested data:  • “Landing” zones (OnePAM External LDD & MADP External Data Domain) with Party data changes  • “Main” zones (OnePAM Main LDD & MADP Main Data Domains) with Involved Party attributes.  3. Only data passing through Data Ingestor & Data Distributor can be stored in the landing zones.  • The Data Distributor is the only component that can update the Party Data Platform landing zones*  • The Party Data Platform landing zones are Read-Only for everyone but the Data Distributor.  • The Data Distributor only updates the Party Data Platform landing zones with Data Ingestor & Data Refresher provided data.  • The Party Data Platform landing zones are also Read-Only for the Data Distributor otherwise to ensure their integrity  4. The Data Distributor only acts on changed Ingested Party Data (deltas must exist).  • All its input records must have at least one changed attribute for any data to be updated in the Landing or Main zones.  • Full refreshes are first processed by the Data Refresher which provides the Data Distributor with the remaining deltas to process.  • Reconciliations are first processed by the Data Reconciler which provides the Data Distributor with deltas for the Main zones only  5. The Data Distributor does not implement the business consequence of ingested Party data updates.  • It updates ingested Involved Party data in the Main OnePAM LDD and MADP Main Data Domains.  • It updates changed attributes or sets flags on matched Involved Party objects (e.g. flag an Involved Party as an incapable).  • It creates & deletes Involved Party objects and associated relationships (e.g. deleting removed Legal Reps that are not customers).  • It will not apply “business logic” on other attributes (e.g. it will flag an incapable but will not take away mandates).  • Derived and downstream alterations must be done by “Business Event” services acting on changes by the Data Distributor.  26  *including data stewardship Data Reconciler  MADP  High-level* End-to-end Architecture of the Data Distributor  27  Data Distributor   Initial Load  Unite Data  Lake (UDL)  DD Store  UUID/EM table Record/Attr table Error table  4  Data Refresher  OnePAM  Daily Load  Refresh Load  OnePAM  MADP  Policy Table Record/Attr table  Same table  Upload Response Read Read Upload/  Update  Upload/  Update Response  Entity Match Insert changed  attributes  Decide action  on attribute  Validate attribute  update  Process update  errors  Response  1  Data  Ingest DI  2  Only when refresh/reconciliation is triggered  4 4  5  3 7  6  7 8 8  9 10 Configuration  External LDD  Main LDD  Cassandra  External Data  Domain  (Ingested  Parties)  Main  Data  Domain  (Involved  Parties)  ** Doesn’t exist yet.  *In the phased approach not all components are there and at a lower level of abstraction (File vs API, External vs Main) there are some variations  Data Steward  Tool  Event  Layer  11 12  Disambiguation service**  Ingest flow specific logic Generic flow of the Data Distributor  Preprocessing  1  • Read input  2  • Entity matching  • Local (DD  UUID)  • Remote  disambiguation  3  • (if needed) Hand off to Refresher  or Reconciler for  removing  unchanged  Parties  11  Preparing  4  • Read existing  values (API)  5  • Identify changed  attributes & store  for post processing  validation  6  • Evaluate update  policy (for  updating Main  zones)  Uploading  7  • Upload to target  • API-calls  • Files  • Create/Change  /Delete  8  • Parties/  Relationships/  Attributes  • Capture  responses  • API response  • Events  Postprocessing  9  • Validate  responses  • Check-off  stored  changed  attributes  10  • Process failures  • Response  errors (API)  • Decide out-of time (Events)  • The Data Distributor may send out status events to an event layer to be picked up by management tools for human or  automated action.  12  • A human management interface (like the data Stewardship tool) should have access to the Data Distributor to view logged  messages, change configuration, adapt policies and restart or retry to upload records that failed before.  28 Functional architecture of the Data Distributor  Process triggers & human  interface commands  Read Data Ingestor  files & UDL extracts  Receive OnePAM  Notifications & MADP events  Send files to  OnePAM & MADP  Data Distributor  Configuration driven flows to  manage data distribution to  OnePAM & MADP  Input Interfaces  File  Read & update  OnePAM & MADP APIs  Output Interfaces  API  Input & output file specific  configuration parameters,  target store/Interface/security  configuration  Event  File  API  Event  Data Distribution flow orchestrator  Initial  load  Daily  upload  Refresh  Party, Attribute & Relation  specific decisions (“update  when different, update when  changed, no update”)  Parameterization for specific  exception handling (log, send  event, retry, event timeout…)  For each type of error,  implement the appropriate  course of action (log, send  Parametrization  Configuration  management  Policy  management  Exception  management  Daily  Update  DB  Reconciliation  Data Management  Input file management  Object Modeling  Output file management  Notification management  API management  Database management  Party  management  Relationship  management  Attribute  management  Send status events like  errors, start & end of  processing  Access Data Distributor  store  Contains logic to treat each  and every data object in a  parameter driven way  (formatting, recomposition,  entity matching, attribute  comparison, DD-UUID  creation, disambiguation)
